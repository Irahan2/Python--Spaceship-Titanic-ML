# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MOHHO_rhaWu9n70Z8rjzRizGfAi3Rdlh
"""

!pip install tensorflow_decision_forests
import tensorflow as tf
import tensorflow_decision_forests as tfdf
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('/content/train.csv')
df.head()

df.describe()
df.info()
sns.countplot(x='Transported', data=df)
plt.show()
df.select_dtypes(include=[np.number]).hist(figsize=(10, 10))
plt.tight_layout()
plt.show()

df.drop(['Name', 'PassengerId'], axis=1, inplace=True)

missing_values = df.isnull().sum().sort_values(ascending=False)

boolean_columns = ['CryoSleep', 'VIP']
for col in boolean_columns:
    df[col] = df[col].fillna(0).astype(int)

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())

df[['Deck', 'Cabin_num', 'Side']] = df['Cabin'].str.split('/', expand=True)
df.drop('Cabin', axis=1, inplace=True)

def split_dataset(dataset, test_ratio=0.20):
    test_indices = np.random.rand(len(dataset)) < test_ratio
    return dataset[~test_indices], dataset[test_indices]

train_df, test_df = split_dataset(df)

train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label='Transported')
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label='Transported')

print(df.head())
print(df.describe())

import tensorflow_decision_forests as tfdf

models = tfdf.keras.get_all_models()

print(models)

model = tfdf.keras.RandomForestModel()

import tensorflow_decision_forests as tfdf

model = tfdf.keras.RandomForestModel()

model.compile(metrics=["accuracy"])

model.fit(train_ds)

tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0, max_depth=3)

import pandas as pd
import tensorflow_decision_forests as tfdf
import matplotlib.pyplot as plt

# Assuming 'test_df' is already defined and preprocessed appropriately
# Create a TensorFlow dataset from the Pandas DataFrame for evaluation
valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label='Transported')

# Assuming 'model' is your trained TensorFlow Decision Forests model
# Get the inspector for the trained model to access training logs and other internals
inspector = model.make_inspector()

# Extract the training logs
logs = inspector.training_logs()

# Plot Out-of-Bag (OOB) evaluation accuracy over the number of trees
plt.figure(figsize=(10, 5))
plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])
plt.xlabel("Number of trees")
plt.ylabel("OOB accuracy")
plt.title("OOB accuracy by number of trees")
plt.show()

# Print the overall evaluation metrics of the model
oob_evaluation = inspector.evaluation()
print("OOB Evaluation:", oob_evaluation)

# Evaluate the model using the validation dataset
evaluation_results = model.evaluate(valid_ds, return_dict=True)
print("Validation Evaluation:", evaluation_results)

# Print formatted evaluation metrics
for name, value in evaluation_results.items():
    print(f"{name}: {value:.4f}")

# Display the feature importances
feature_importances = inspector.variable_importances()["NUM_AS_ROOT"]
print("\nFeature Importances (NUM_AS_ROOT):")
for feature, importance in feature_importances:
    print(f"{feature}: {importance}")





